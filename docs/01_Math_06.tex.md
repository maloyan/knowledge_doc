Условная вероятность и независимость событий. Теорема Байеса. Условные распределения. {#1.06}
-------------------------------------------------------------------------------------

Пусть $(\Omega, \mathcal{A}, \mathbb{P})$ - некоторое вероятностное
пространство.

**Условной вероятностью** события $A$ при условии события $B$ с
$P(B) > 0$ называется величина
$$P(A|B) = \frac{P(A\cap B)}{P(B)} = \frac{P(AB)}{P(B)}$$

![Пересечение событий](images/ab_intersection.png)

События $A$ и $B$ называются **независимыми**, если $$P(AB) = P(A)P(B)$$

![Визуализация формулы полной
вероятности](images/total_probability.png){width="30%"}

Пусть события $B_1, \dots, B_n$ образуют полную группу, т.е.

1.  $B_i \cap B_j = \varnothing$

2.  $\bigcup\limits_{i=1}^{n} B_i = \Omega$

3.  $P(B_i) > 0 \;\; \forall i$

Тогда
$A = A \cap \Omega = A \cap \bigcup\limits_{i=1}^{n} B_i = \bigcup\limits_{i=1}^{n} A \cap B_i$,
причем $(AB_i)\cup(AB_j) = \varnothing$\
Тогда верна **формула полной вероятности**:
$$P(A) = \sum\limits_{i=1}^{n} P(B_i) \cdot P(A | B_i)$$

**Теорема Байеса**. $$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

Если же представить $P(B) = \sum \limits_{i=1}^{N} P(B|A_i)P(A_i)$, то
формулу Байеса можно записать как
$$P(A_i|B) = \frac{P(A_i) \cdot P(B|A_i)}{\sum\limits_{i=1}^{n} P(A_i) \cdot P(B|A_i)}$$

Формула Байеса позволяет «переставить причину и следствие»: по
известному факту события вычислить вероятность того, что оно было
вызвано данной причиной. При этом необходимо понимать, для применения
теоремы причинно-следственная связь между $A$ и $B$ не является
обязательной.
