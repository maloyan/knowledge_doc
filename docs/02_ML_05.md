Ансамблирование моделей: мажорантное голосование, блендинг, бустинг, бэгинг. {#2.05}
----------------------------------------------------------------------------

**Ансамбль методов** - это способ использования нескольких обучающих
алгоритмов с целью получения лучшей эффективности предсказания
(классификации или регрессии), чем можно было бы получить от каждого
обучающего алгоритма по отдельности. Ансамбль методов не бесконечен:
состоит из конкретного конечного множества альтернативных моделей.

**Мажорантное голосование** - ансамблирование моделей, при котором в
качестве результата предоставляется ответ, который дало большинство
базовых моделей ансамбля.

### Блендинг {#блендинг .unnumbered}

Предположим, что мы можем обучить $T$ базовых моделей. После этого мы
обучаем комбинирующую модель верхнего уровня (метамодель), входом для
которой являются выходы базовых.

1.  Разбиваем обучающую выборку на две части

2.  На первой части обучаем базовые модели

3.  На второй части получаем ответы базовых моделей, обученных ранее, а
    затем обучаем метамодель на этих ответах

4.  На тестовой выборке получаем ответы базовых моделей, к которым затем
    применяем метамодель и получаем итоговый результат

![image](images/blending_base.png){width="15cm"}

Проблема классического блендинга заключается в том, что ни базовые
алгоритмы, ни мета-алгоритм не видят всей обучающей выборки. Поэтому
можно усовершенствовать подход (подход \"вширь\"):

-   Разбиваем обучающую выборку на две части

-   На первой части обучаем базовые модели

-   На второй части получаем их ответы (метапризнаки), а затем обучаем
    метамодель на этих ответах

-   Повторяем пп. 2-3 $M \geq 2$ раз для других разбиений обучающей
    выборки

-   На тесте сначала получаем $M$ наборов выходов базовых моделей,
    обученных на разных разбиениях, затем для каждого набора запускаем
    соответствующую метамодель

-   Усредняем $M$ ответов метамоделей

![image](images/blending_mean.png){width="15cm"}

### Бустинг {#бустинг .unnumbered}

**Бустинг** --- это техника построения ансамблей, в которой
предсказатели построены не независимо, а последовательно. Бустинг
использует идею о том, что следующая модель будет учится на ошибках
предыдущей. Они имеют неравную вероятность появления в последующих
моделях, и чаще появятся те, что дают наибольшую ошибку.

В то время как бустинг алгоритмически не ограничен, большинство
алгоритмов бустинга состоит из итеративного обучения слабых
классификаторов с целью сборки их в сильный классификатор. Когда они
добавляются, им обычно приписываются некоторым образом веса, которые,
обычно, связаны с точностью обучения. После того, как слабый
классификатор добавлен, веса пересчитываются, что известно как
\"пересчёт весовых коэффициентов\". Неверно классифицированные входные
данные получают больший вес, а правильно классифицированные экземпляры
теряют веc. Тем самым последующее слабое обучение фокусируется больше на
примерах, где предыдущие слабые обучения дали ошибочную классификацию.
Два важных примера алгоритмов бустинга: адаптивный бустинг (`AdaBoost`)
и градиентный бустинг.

### Бэггинг {#бэггинг .unnumbered}

**Бэггинг** -- технология классификации, где в отличие от бустинга все
базовые модели обучаются и работают параллельно (независимо друг от
друга). Идея заключается в том, что модели не исправляют ошибки друг
друга, а компенсируют их при голосовании. Базовые модели должны быть
независимыми, это могут быть модели основанные на разных группах методов
или же обученные на независимых наборах данных. Во втором случае можно
использовать один и тот же метод.
