Функции потерь для задач машинного обучения. Градиентный спуск. {#2.02}
---------------------------------------------------------------

Чтобы определить, какие значения параметров модели будут лучшими, нам
нужен способ количественной оценки «непригодности» параметров. И этим
способом будет специальная функция, которая принимает на вход параметры
модели и определяет, насколько плохо они работают. В машинном обучении
она называется **функцией потерь** (loss function).\
**Градиентный спуск** -- это метод нахождения локального
максимума/минимума функции с помощью движения вдоль градиента. В нашем
случае, для loss ф-ции.

Пусть у нас есть функция $f(x)$. Для того, чтобы найти минимум функции:

1.  Вычислим производную функции $f$ по аргументу $x$;

2.  Изменим $x$ на значение, пропорциональное производной функции в
    точке $x$ со знаком минус;

3.  Будем повторять, пока не достигнем сходимости (пока значение функции
    потерь не достигнет заданного $\epsilon$).

until converge:\
$x := x - \alpha \cdot f'(x)$

где $\alpha$ --- размер шага вдоль градиента или скорость обучения
(learning rate).\
В случае, когда функция $f$ зависит от многих переменных
$x \rightarrow (x_{1}, x_{2}, ..., x_{m}), f \rightarrow f(x_{1}, x_{2}, \dots,x_{m})$,
вместо производной по одному параметру $x$ необходимо вычислять градиент
функции, то есть вектор:

$\triangledown f = \begin{bmatrix} 
\frac{\partial f}{\partial x_{1}}\\  \frac{\partial f}{\partial x_{2}}\\  \dots\\ \frac{\partial f}{\partial x_{m}} \end{bmatrix}$

Note: При обновлении параметров необходимо сначала сохранить все
параметры, а затем вычислять новые с использованием сохраненных. В ином
случае мы обновим один параметр, а при обновлении второго параметра
будем использовать уже новый первый параметр.\
**Градиент** -- вектор, указывающий направление, в котором функция
быстрее всего возрастает, поэтому в алгоритме мы делаем шаги в
противоположном направлении.
