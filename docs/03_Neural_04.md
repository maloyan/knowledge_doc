Способы искусственного расширения набора данных для увеличения обобщающей способности. Аугментация, генерация, симуляция. Перенос обучения (Transfer learning). {#3.04}
---------------------------------------------------------------------------------------------------------------------------------------------------------------

**Аугментация** -- генерация наборов данных на основе имеющихся данных.
К имеющимся данным применяются различные способы искажения: например,
для изображений могут использоваться различные геометрические
преобразования, искажения цвета, кадрирование, поворот, добавление шума
и иные. Для числовых данных могут использоваться такие искажения, как
добавление объектов с усреднёнными значениями, смешивание с объектами из
другого распределения, добавление случайных выбросов.

Про генерацию и симуляцию я не нашел норм инфы, но могу поделиться
мнением как я себе это представляю, и думаю, очень хорошо, если бы
кто-то из богов ML помог уточнить (например, Саит).

**Генерация** -- создание искуственных данных на уровне датасета. То
есть, аугментация является частным случаем генерации.

**Симуляция** -- создание искусственных данных уже не на уровне
датасета, а на уровне эмбеддингов (я не про таргеты, а про внутренние
представления данных из датасета).

### Transfer learning {#transfer-learning .unnumbered}

Смысл **transfer learning** заключается в том, чтобы обучать модели,
формировать значения весов, а затем применять обученные модели для
решения других задач. Работает не всегда, т.к. например CNN-ы довольно
разнообразные, они учаться извлекать какие-то признаки с входных данных.
Эти веса для извлечения можно использовать для решения своих задач с
извлечением признаков. Но надо дообучать модели.

Если датасеты близкие, то можно просто выкинуть последний слой с $N$
классами, ставить другой последний слой с нужным $M$ количеством
классов, и дообучаем веса только на последнем слое. Так тоже делают! На
медицинские CNN так делать вообще нельзя, опасно.
