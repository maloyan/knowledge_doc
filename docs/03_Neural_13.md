Вопросы практической реализации нейронных сетей в условиях ограничения вычислительных ресурсов. Дистилляция. Прунинг. Квантизация. {#3.13}
----------------------------------------------------------------------------------------------------------------------------------

Зачем это всё нужно?

-   Ускорение модели - чтобы она работала быстрее

-   Оптимизация модели под конкретное устройство - телефон мобильный,
    специфические видеокамеры и т.д.

-   Сжатие модели - чтобы занимала меньше места на диске или в памяти

Зачастую методы по ускорению, сжатию, оптимизации схожи, так как на
устройстве может быть доступен только специфический набор операций для
нейросети (например, доступны не все функции активации, не все способы
сверток и т.д.)

### Прунинг

**Прунинг** - это удаление связей в нейронных сетях (разреживание).

![Прунинг. Слева - полносвязная сеть (MLP). Справа - сеть после удаления
связей и некоторых нейронов (его связи с другими
нейронами)](images/pruning.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}

**Как выбирать удаляемые связи?**

-   Чтобы обнуление веса наименьшим образом влияло на качество, надо
    удалять наименее значимые связи, например те, у которых наименьшие
    веса (так как они дают наименьший вклад в результирующее решение
    нейросети)

Однако появляется проблема (несмотря на то, что удаленные веса малы,
они, всё же не нулевые и имеют некоторое влияние на итоговые активации)
- при удалении связей может существенно падать точность модели.\
Возможные решения:

-   при обучении нейросети добавлять $l_1, l_2$ - регуляризацию, чтобы
    появлялось больше весов с маленьким весом.

-   производить дообучение модели после обнуления весов, чтобы
    перераспределить ту ошибку, которая появилась после того, как мы
    удалили хоть и малозначащие, но тем не менее вносящие вклад веса.

![Схема прунинга. Имеется сеть, мы оцениваем важность нейронов, связей.
Удаляем наименее значимые связи. Далее, на оставшихся весах дообучаем
сеть и согласно некоторому критерию (например, достигли некоторого
качества или объема), решаем, продолжать прунинг или нет.
](images/prun_scheme.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}

С точки зрения вычислений выгоднее удалять не связи из графа, а нейроны
целиком или карты или, даже, слои.

![Прунинг карт. $n_i$- кол-во входных карт, $n_{i+1}$ - кол-во выходных
карт. $K=p\times q$, где $p, q$ - размерность фильтра. Если хотим
удалить карту нужно удалить выделенный столбик и строку
(синие).](images/card_pruning.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}

Детали алгоритма

-   Удаление карты происходит путем удаления весов с минимальной нормой
    веса (сумма квадратов или сумма абсолютных значений)

-   Эта же норма добавляется к функции потерь с некоторым весом

-   Удаление происходит постепенно и итеративно вместе с дообучением

-   Критерий остановки - либо достижение порога по качеству модели, либо
    достижение необходимого вычислительного бюджета.

### Квантование

Архитектуру не трогаем, а работаем с самими значениями весов.

**Квантование** - уменьшение битности параметров нейронной сети.\
По умолчанию при обучении нейросети веса 32-битные (float32), могут быть
и double. Если сеть большая, то она занимает очень много места.

-   При уменьшении битности параметров вычисления можно проводить
    быстрее

-   Существенно уменьшается размер модели

**Методы квантования**

-   Обучение модели в полной точности, а потом округление весов до
    нужного количества бит

-   Как правило, после округления идет дообучение (возможно итеративно,
    как в случае с прунингом)

-   Есть методы, позволяющие обучать сразу квантованные модели

**Бинарные нейронные сети** - экстремальный случай квантования, когда
веса имеют только два значения.

В таком виде обучение модели градиентным спуском затруднено, так как
пространство дискретное

![Бинарные нейронные сети. Есть однобитные веса и однобитные активации.
Справа в строку выписаны веса (верхняя строка) и часть активации (нижняя
строка) и над ними производится операция $xnor$ - если повторяются
значения, то возвр. 1, а когда значения различны, то возвр. -1. Затем, в
качестве ответа идет сумма всех элементов](images/bin_nets.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}

Нужно различать квантование весов и квантование значений, которые
возникают при проходе по сети. Т.к. например, мы можем иметь
квантованные (даже бинарные) веса, а когда считаем сумму произведений
(напр. свертку), то не обязательно затем квантовать. И сети тоже
отличатся - активации перед подачей на следующий слой могут
квантоваться, а могут и нет.

### Дистилляция

-   Идея - передать знания от Учителя (большая нейронная сеть или
    ансамбль моделей) к Студенту (маленькая нейронная сеть)

![Дистилляция. На схеме - Учитель (большая сеть) и ученик (малая сеть).
При этом ученик использует как ground trurh - разметку, так и знания
учителя. ](images/distillation.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}

Сделаем допущение - будем рассматривать классификационную нейронную
сеть. Возникает вопрос, почему использование учителя может работать
лучше, чем просто обучение? Ответ:

-   В задаче классификации разметка осуществляется путем выбора одного
    наиболее подходящего класса. Обученная нейронная сеть же выдает
    распределение по классам, которое содержит дополнительную информацию
    (при этом распределение не будет являться onehot. Argmax по этому
    вектору дает нужный ответ, но и у других классов вероятность
    $\neq 0$. Т.е. сеть говорит, что картинка в целом собака, но еще
    немного похожа на кошку, свинью и лошадь. И эта информация, что
    ответ не только собака, но и есть схожесть с другими классами -
    важна, так как в случае человека есть априорные знания, что какая-то
    вещь похожа на другие в какой-то степени. И эта информация будет
    передана Ученику от Учителя).

-   Можно расширить обучающий датасет, используя выход Учителя как
    аннотацию. (есть размеченные данные, запускаем на них учителя и
    получаем новую разметку, таким образом получаем новые данные)

При обучении применяется функция потерь Softmax с температурой:
$$q_{i}=\frac{exp(\frac{z_i}{T})}{\sum_{j}exp(\frac{z_j}{T})}$$ где
$z_i$ - активации\
Свойства:

-   При $T=1$ - обычный Softmax

-   При $T\rightarrow\infty$ вероятности будут все больше выравниваться
    (примерно будет $\frac{1}{n}$)

-   Где-то в промежутке станет доступна для обучения дополнительная
    информация из распределения (сам Хинтон называл это \"dark
    knowledge\")

Дистилляционная функция потерь:
$$\mathcal{L}(x;W)=\alpha\ast \mathcal{H}(y,\sigma(z_s;T=1))+\beta\ast\mathcal{H}(\sigma(z_t;T=\tau),\sigma(z_s, T=\tau))$$

Здесь: $\mathcal{H}$ - некая функция потерь (напр., кросс-энтропия).
Левое слагаемое - обучаем Ученика на ground truth метках (в формате
onehot encoding) с температурой $T=1$. Правое слагаемое - Ученика
обучаем с температурой $T=\tau$ и в качестве меток берем выход учителя
($z_t$)

![Дистилляция знаний. Вход идет в Учителя и Ученика. У Ученика при
температурном коэфф = 1 делаем hard prediction (кросс-энтропийная ф.п.,
обычное обучение). Но хотим еще и привлечь данные от Учителя, применяем
температурный Softmax, получаем распределение (soft labels) и сравниваем
распределения (для этого выход Ученика тоже пропускаем через
температурный Softmax и сравниваем уже этот выход (soft prediction) с
выходом Учителя (soft labels). Тут уже метка не важна. Веса Учителя
зафиксированы (считается, что он хорошо обучен), обучается только
Ученик)](images/dist_tech_stu.png)

[\[fig:my\_label\]]{#fig:my_label label="fig:my_label"}
