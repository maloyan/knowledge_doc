Оценка устойчивости моделей машинного обучения к внешним воздействиям. Формальная верификация моделей. SAT / SMT решатели, линейное программирование и проверка теорем, неполная верификация. Чувствительность моделей к шуму. {#4.03}
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Под **устойчивым** (надежным) машинным обучением обычно понимается
устойчивость (надежность) алгоритмов машинного обучения.

Чтобы алгоритм машинного обучения считался надежным, либо ошибка
тестирования должна согласовываться с ошибкой обучения, либо
производительность должна быть стабильной после добавления некоторого
шума в набор данных.

При этом важно, что мы отмечаем именно проблемы (изменения) в данных.
Ничего не говорится о природе этих изменений.

Другой важный вопрос, который часто не акцентируется. Мы говорим о
добавлении шума к исходным данным (данным для обучения) потому, что мы
не знаем, вообще говоря, ничего о реальных данных. Поэтому единственный
способ как-то представить возможные тестовые данные -- это получить их
из реальных путем добавления возмущений.

*Оценка устойчивости зависит от того, насколько точно (репрезентативно)
тренировочные данные представляют реальные (тестовые) данные*

Google (Deepmind) в обзорной публикации своей исследовательской группы
Robust and Verified Deep Learning Group отмечает, что системы машинного
обучения по умолчанию не являются надежными.

3 базовых правила:

I. Вы не должны тренироваться на данных, которым не полностью доверяете
(из-за возможного отравления данных)

II\. Вы не должны позволять никому использовать вашу модель или наблюдать
за ее работой (из-за кражи модели и атак черного ящика).

III\. Вы не должны полностью доверять предсказаниям вашей модели (из-за
возможных состязательных примеров).

Как можно оценивать устойчивость систем машинного обучения? Как
говорилось выше, отсутствие устойчивости -- фундаментальное свойство
систем машинного обучения. (всегда можно придумать состязательный
пример)

Во-первых, можно рассматривать системы машинного обучения как
законченные программные продукты, для которых существуют подходы к
ограничениям (проверке, фильтрации) входных данных и проверке работы
системы в реальном времени (assertion). Это точно также применимо и к
программной системе, которой является обученная модель. Естественно, это
не гарантирует, в общем случае, устойчивости, но это "лучше чем ничего".
По крайней мере, присутствие (отсутствие) таких проверок может
использоваться при сравнении моделей.

Проверка работы в реальном времени, если она должна делать что-то больше
журналирования результатов, также зависит от предметной области. В
каких-то случаях можно остановить работу системы при срабатывании
проверок (как правило -- для всех систем, не связанных с управлением в
реальном времени), в каких-то случаях -- такое может быть невозможным.

Оценка устойчивости:

Во-первых, это *верификация устойчивости*, которая обеспечивает
теоретические гарантии обеспечения уровня возмущений исходных данных, не
влияющего на работу сети.

Второй подход -- это собственно *количественная оценка* устойчивости,
которая вводится как оценка трудности нахождения исходных данных,
которые приводят к неверным результатам работы. Интуитивно понятно, что
чем сложнее генерировать такие входные данные, тем надежнее модель.

Из общих соображений, верификация (теоретическое подтверждение)
является, конечно, более предпочтительной. Этот подход является крайне
интересным, но в настоящий момент он испытывает проблемы с
масштабируемостью. Причину проблем можно объяснить достаточно просто.

Формальная верификация означает формальное же описание проблемы (в
данном случае -- системы машинного обучения). (Например -- записать
(представить) модель в виде набора логических утверждений.)

(Противоречие: при создании модели мы набираем большое число фичей,
чтобы найти скрытые закономерности, то есть моделирование требует
увеличения размерности, верификация -- уменьшения.)

Смысл верификации состоит в доказательстве того, что при известных
ограничениях на входные значения, выходные значения будут находиться в
заданных (известных) границах.

Есть 4 группы подходов к формальной верификации систем машинного
обучения 1. SAT/SMT решатели 2. Линейное программирование 3. Проверка
теорем 4. Неполная верификация

### SAT/SMT

**Satisfiability (SAT) и Satisfiability Modulo Theories (SMT)** -- это
задача выполнимости булевых формул и задача выполнимости формул в
теориях.

SAT -- это задача проверки выполнимости булевой формулы, состоящая
только из имён переменных, скобок и операций И, ИЛИ и (HE).

SMT-формула --- это формула в логике первого порядка, в которой
некоторые функции и предикатные символы имеют дополнительную
интерпретацию.

Проверяются программные ограничения и ограничения, налагаемые на
переменные. Точно также и для системы ML - ограничения на сеть и
ограничения на элементы сети.

![сверху верификация программ, снизу
модели](images/4_3_sat_smt.png){width="0.7\linewidth"}

[\[fig:sat\_smt\]]{#fig:sat_smt label="fig:sat_smt"}

Модель системы и проверяемое свойство выражаются в логике высказываний и
записываются в виде нормальной конъюнктивной формы (CNF), которая затем
проверяется автоматическим SAT-решателем.

Вывод решателя двоичный: SAT означает наличие контрпримера, UNSAT
подразумевает отсутствие каких-либо контрпримеров, и, следовательно,
указывает на то, что указанное высказывание справедливо для системы.

Теории выполнимости по модулю (SMT) работает аналогично SAT, но
позволяет использовать теории, выходящие за рамки логики высказываний,
такие, как линейная арифметика.

SAT - двоичные значения, поэтому он для бинарированных нейронных сетей
(BNN), где веса и активации, преимущественно, бинарные.

Соответственно, SMT решатели используются для верификации DNN с
цифровыми (целыми и вещественными) параметрами.

Далее предположим, что существует семейство операций $\Delta$, которые
мы называем манипуляциями, которые определяют модификации изображения,
под которым классификационное решение должно оставаться неизменным в
регионе $\eta$. (Такие манипуляции могут представлять собой, например,
погрешности камеры, изменение угла камеры или замену параметров
(features).)

• Решение безопасное для ввода $X$ и региона $\eta$ с учетом набора
манипуляций $\Delta$, если применение манипуляций к $X$ не изменяют
классификацию.

### Линейное программирование

Верификация на основе линейного программирования (LP) работает путем
определения верифицируемой системы как набора линейных ограничений с
максимизацией или минимизацией заданной целевой функции.

![сверху верификация программ, снизу
модели](images/4_3_lp.png){width="0.7\linewidth"}

[\[fig:lp\_prog\]]{#fig:lp_prog label="fig:lp_prog"}

Для верификации устойчивости к атакам, целью проверки является
нахождение минимального шума (изменения данных), при котором ограничения
сохраняются (удовлетворяются), а классификация -- меняется. Это
проиллюстрировано на рисунке ниже, так же в сравнении с верификацией
программ.

Для DNN одной из проблем использования линейного программирований
(соответственно, линейных ограничений) являются нелинейные функции
активации.

Соответственно, для целей верификации они могут быть заменены линейными
аппроксимациями.

### Проверка теорем

Доказательство теорем - это тип формальной проверки, в которой система и
ее свойства определены математически, и свойства проверяются для системы
по правилам естественной дедукции.

Для проверки система должна быть представлена в виде логической модели с
формальной математической нотацией. Свойство аналогично выражается как
формальная цель доказательства. Цель состоит в том, чтобы использовать
аксиомы и правила, выведенные из этих аксиом, для проверки свойств.

Такое представление требует глубокого знания процессов, лежащих в основе
системы для ее реалистичного моделирования.

![сверху верификация программ, снизу
модели](images/4_3_theor.png){width="0.7\linewidth"}

[\[fig:theor\_check\]]{#fig:theor_check label="fig:theor_check"}

### Неполная верефикация

Под этим понимается процесс верификации некоторого приближения системы.

Неполная верификация часто использует абстрактную интерпретацию,
линейную аппроксимацию и другие подобные подходы для формального
моделирования системы. В результате, модель системы модель не является
точным представлением реальной системы, а, скорее, некоторым ее
избыточным приближение.

Важно отметить, что моделирование/тестирование, которое также дает
неполные результаты, не следует путать с неполной верификацией.

Неполное результаты - в резульате рассмоторения системы как черный ящик.

Неполная верификация - система \"белый ящик\", просто модель упрощена.

![сверху верификация программ, снизу
модели](images/4_3_notfull.png){width="0.7\linewidth"}

[\[fig:not\_full\]]{#fig:not_full label="fig:not_full"}

Очевидно, что упрощение положительно влияет на масштабируемость, но,
вместе с тем, отсутствие опровергающих примеров для упрощенной модели не
означает того же самого для полной модели.

### Чувствительность к шуму

Сеть должна устойчиво классифицировать данные из обучающих примеров, а
также в окрестности существующих данных (образцов)

Noise Sensitivity Score - NSS -- оценка чувствительности к шуму.

Чем выше среднее минимальное (по всем данным из имеющегося набора)
возмущение (чем больше круги), которое требуется для неправильной
классификации образца, тем надежнее DNN по отношению к состязательным
атакам.

При всей ясности такого подхода, вопрос, который возникает немедленно --
каковы гарантии, что мы нашли все состязательные примеры (чтобы
декларировать минимальное расстояние)?

Также вычисление такой оценки может быть достаточно затратным.
